<!DOCTYPE html>
<html><head><link rel="stylesheet" href="https://s.brightspace.com/lib/fonts/0.6.1/fonts.css"></head><body style="color: rgb(32, 33, 34); font-family: Lato, sans-serif; font-size: 12px;"><p><span style="font-size: 20px;"><strong>Project Development Guidance: Week 6</strong></span></p>
<p><span style="font-size: 16px;">Before proceeding, ensure that your group has carefully considered all guidance given <a href="/d2l/common/dialogs/quickLink/quickLink.d2l?ou=116256&amp;type=content&amp;rcode=E595AE0C-8A63-41EC-9004-7FB5722070E0-821603" target="_blank" rel="noopener">previously</a>. What follows here assumes that you've already designed a high-level project architecture modularized in a way similar to the following:</span></p>
<ol>
<li style="font-size: 16px;"><span style="font-size: 16px;">There's a module that encapsulates the main data structure for representing problem instances. This module exports the problem instance query/modifier procedures that allow client modules to manipulate problem instances (including in the ways described in the previously provided guidance).</span></li>
<li style="font-size: 16px;"><span style="font-size: 16px;">There is (or will be) a module that parses input data to build the initial problem instance (and that detects invalid input). This likely makes use of procedures provided by module 1 to build a problem instance as the input is read.</span></li>
<li style="font-size: 16px;"><span style="font-size: 16px;">There is (or will be) a module that writes a solution to the output, given a solved problem instance. This possibly makes use of procedures provided by module 1 to query a solved problem instance as the output is written.</span></li>
<li style="font-size: 16px;"><span style="font-size: 16px;">There is (or will be) a module that implements the problem-instance-solving logic (i.e., a primary "solve" procedure and any supporting routines). This certainly makes use of query/modifier procedures provided by module 1.</span></li>
<li style="font-size: 16px;"><span style="font-size: 16px;">There is (or will be) a main module that integrates all of the above into a working program.</span></li>
</ol>
<p><span style="font-size: 16px;">Further, what follows assumes that you've already designed your project's main data structure and that you've implemented it, thoroughly tested it, and reviewed it as a group. (This isn't to say that you won't revise this design some more as you gain experience with the implementation.)</span></p>
<p><span style="font-size: 16px;">Even if basic versions of the remaining modules haven't been implemented yet, it should at least be possible specify the interface of each and to code "stubs" for its various procedures. That is, it should be possible to begin composing the modules into an integrated (if functionally incomplete) program. In fact, in a well-designed solution, where the interfaces between modules have been well thought out and are therefore relatively stable, it should be possible change the internal implementations of modules without needing to reimplement other modules. In other words, modules should exhibit low coupling.</span></p>
<p><span style="font-size: 16px;">For the imperative version of the project, remaining guidance will focus on the problem-instance-solving logic. However, groups should consult with the instructor if they have questions about other modules or other aspects of the project.</span></p>
<p><strong><span style="font-size: 16px;">A Quick Note on Modular Testing</span></strong></p>
<p><span style="font-size: 16px;">Note that it's not necessary to fully implement all of the above modules before testing each thoroughly. All programming languages support the ability to hard-code static instances of custom data structures. So, even before module 2 (the input-reading module) is ready, it should be possible for someone (perhaps another team member) to test module 3 (the output-writing module). All they need are some hard-coded solution instances to process. The same is true for testing module 4 (the solver). You might wish to use a unit-testing framework to help automate the testing process, although this isn't mandatory.</span></p>
<p><span style="font-size: 16px;"><strong>Pause and Take Stock Now</strong></span></p>
<p><span style="font-size: 16px;">This is a good time to pause and consider the following as a group:</span><span style="font-size: 16px;"></span></p>
<ul>
<li><span style="font-size: 16px;"><em>Project governance and management issues:</em> How well is our project-development effort proceeding overall? What did we identify as our overarching goals, and are we on track to meet them? Are our group policies and standards serving us well? Are we following our established plans? Do any previous decisions need to be revisited? Are there governance/management issues not previously considered that need our attention?</span></li>
<li><em><span style="font-size: 16px;">Key design issues:</span></em><span style="font-size: 16px;"> Are there any architectural design, data structure design, or algorithm design details that need to be addressed? So far, does it appear that our designs are fit for purpose?</span><span style="font-size: 16px;"></span></li>
<li><em><span style="font-size: 16px;">Key quality assurance issues:</span></em><span style="font-size: 16px;"> Are our approaches to unit testing, integration testing, and functional testing appropriate? Are we continuing to systematically develop a sufficiently robust and explicit test plan? Are we also ensuring high-quality (and standards-compliant) designs, code, and documentation, not only through testing but also through regular group review activities? Can we clearly articulate the criteria we use in our reviews?</span></li>
<li><span style="font-size: 16px;">Will we be ready to discuss the above at a post-reading-break meeting with the instructor and to present a basic but working version of the imperative solution? Will all group members be able to discuss all aspects of the program and its connection to important course learning objectives?</span></li>
</ul>
<p><span style="font-size: 16px;"><strong>How to Think about the Solving Process</strong></span></p>
<p><span style="font-size: 16px;">It's helpful to think about how a problem instance would be solved through <em>non-deterministic</em> means: Given a solvable problem instance, if one&nbsp;<em>could</em> simply make a sequence of choices that led to a solution, then checking that this solution correctly satisfied all of the relevant requirements and constraints would be straightforward. </span><span style="font-size: 16px;">For example, if the project was a Sudoku-solving program, then a non-deterministic approach would involve guessing (somehow correctly) the number to fill in at each blank cell, such that all of the numbers in the completed puzzle satisfied the Sudoku rules. Of course, as we considered each successive cell, some choices could be recognized as immediately invalid (based on the contents of other cells already filled in), but the correct choice wouldn't always be fully determined by current contents of other cells. That is, we <em>have</em> to make guesses sometimes (whether or not they're educated guesses). In a non-deterministic paradigm, we assume we can guess correctly (a solution is said to exist if there's some sequence of guesses that works out, even if we haven't specified how those are selected). Our challenge is to code a <em>deterministic</em> algorithm that achieves the same result as a non-deterministic approach would, while avoiding an inefficient brute-force approach. Considering what a <em>non-deterministic</em> approach would look like helps us to organize our thinking about the deterministic approach.</span></p>
<p><span style="font-size: 16px;">In summary, ask yourself the following questions. Given a problem instance:</span></p>
<ol>
<li><span style="font-size: 16px;">What's the sequence of choices to be made? Think of this like a to-do list of guesses to make, such that if all guesses were made correctly for a solvable puzzle then a valid solution would have been found. E.g., in Sudoku, the to-do list is the sequence of blank cells to be filled in.</span></li>
<li><span style="font-size: 16px;">At&nbsp;<em>each</em> choice point in the sequence, what's the range of candidates from which a guess can be chosen? E.g., in Sudoku, this is the set of numbers that are valid for this cell, given the contents of already-filled cells.</span></li>
</ol>
<p><span style="font-size: 16px;">Work out how to visualize the above as a decision tree. Each node of the tree, starting from the originally given root, represents a problem instance. It also represents a choice point, with zero, one, or many candidates to chose from. Each choice leads to a new new problem instance, which serves as the root of a new subtree. Leaves are fully solved instances (choices leading here led to success) or are unsolved instances where the set of candidates choices is empty (choices leading here led to failure). A solution is obtained from a linear path starting at the root and ending at a fully solved leaf.</span></p>
<p><span style="font-size: 16px;">Consider points 1 and 2 (above) in relation to the main "solve" algorithm sketched in the previously provided guidance: Each invocation of "solve" represents a choice point. At any stage in the solution process, the "solve" procedure's invocation stack represents the sequence of choices made so far, as the "to-do" list is processed. And, for any single invocation of "solve", it must consider the next choice in our "to-do" list, make a choice from among a set of candidates (this leads to a modified problem instance with a modified to-do list), and recursively attempt to solves what remains.</span></p>
<p><span style="font-size: 16px;">Because the procedural version of your project must implement a deterministic algorithm, it isn't possible to magically guess the correct choice at each choice point. (For problems with greedy solutions, this is possible, but your project, as approved, must be based on a problem without a greedy solution.) However, it&nbsp;<em>is</em> possible to <em>iterate</em> through the set of candidate choices, trying one after another. Thus, non-determinism is replaced by a depth-first strategy with backtracking. In short, the tree becomes a search space that is explored until a pathway to a solution is discovered (or it is determined that no solution exists).</span></p>
<p><span style="font-size: 16px;"><strong>Coding the Basic Solution</strong></span></p>
<p><span style="font-size: 16px;">The strong recommendation is to start by developing a "solve" algorithm that ignores "nice-to-have" features of your project, and without an excessive focus on optimization. (Of course, obviously poor data structure and algorithm designs should be identified and corrected at this point.)&nbsp; Hopefully, you've already been giving your basic solution plenty of thought, after having read the previously provided guidance.</span></p>
<p><span style="font-size: 16px;">Once the core solution is working, then various enhancements and optimizations can be considered as time permits. A few brief notes about optimization opportunities are touched upon briefly below. When considering what follows, remember: Don't just make guesses about changes that might improve performance. Measure the effects of changes and compare performance profiles based on actual data.</span></p>
<p><span style="font-size: 16px;"><strong>Optimization Opportunity: Improve the Data Structure Design (IMPORTANT)</strong></span></p>
<p><span style="font-size: 16px;">Review the implementations of the algorithms that query/modify your data structures as the solve process unfolds. If these are inefficient, then the solve process will necessarily be inefficient (those support routines will be called a lot). When optimizing, this is almost always the best place to start.</span></p>
<p><span style="font-size: 16px;">As part of this optimization, consider store-compute trade-offs. Is data being stored redundantly within the structure, such that it must be updated in multiple places instead of one? Is data being recomputed over and over again at successive stages of the search, whereas it might be possible to cache a result for subsequent lookup?</span></p>
<p><span style="font-size: 16px;"><strong>Optimization Opportunity: Propagate Constraints (IMPORTANT)</strong></span></p>
<p><span style="font-size: 16px;">Together with data structure (re)design, constraint propagation is an essential part of any attempt to speed up the solve process and warrants very close consideration. In short, this is a main way in which your search strategy moves away from being "brute force" and a little closer to being "greedy" (even if a greedy strategy isn't guaranteed to work).</span></p>
<p><span style="font-size: 16px;">The idea is based on two key observations:</span></p>
<ul>
<li><span style="font-size: 16px;">Each time a set of candidate choices is generated (i.e., each time the solve process arrives at the next choice point), that set can be limited just to the candidates that are valid given the configuration of the given problem instance. For example, with Sudoku, it's usually not necessary to consider the set of all numbers {1, 2, ... , 9}. It's only necessary to consider a subset: those numbers that aren't already ruled out based on the contents of other cells in the same row/column/region.</span></li>
<li><span style="font-size: 16px;">Each time a choice is made by selecting a candidate from the set, this can have the effect of ruling out some candidates at upcoming choice points, thus narrowing the size of the remaining search space. The data structure can be updated in such a way that subsequent candidate sets can be efficiently narrowed.</span></li>
</ul>
<p><span style="font-size: 16px;">A good data structure design affords the ability to propagate constraints in this way. This has the effect of greatly improving performance. (Note: the resulting solve algorithm may still have slow worst-case performance because it may still be exponential, but this doesn't mean that it's not a vast improvement over brute force. The branching factor of the search tree might be much smaller!)</span></p>
<p><span style="font-size: 16px;"><strong>Optimization Opportunity: Reorder the "To-do" List</strong></span></p>
<p><span style="font-size: 16px;">The order in which choice points are considered can have a significant effect on the performance of the solve process. For example, when scheduling final exams, a schedule can often be generated faster by scheduling large, high-enrolment courses first and then scheduling small courses afterwards (into the remaining gaps in the exam schedule). This can be accomplished by performing a sort after creating the initial problem instance but before starting the solve process. This requires that some elements of the problem instance representation can be reordered, and it involves considering how to compare elements of such a collection according to some binary ordering relation. This type of optimization is based on heuristics: It's not guaranteed to always speed up the solve process, although it may tend to do so on average.</span></p>
<p><span style="font-size: 16px;"><strong>Optimization Opportunity: Consider the Order of Candidates at Each Choice Point</strong></span></p>
<p><span style="font-size: 16px;">Similarly to the above: At any particular choice point, the order in which candidates choices are attempted can make a difference. It may be possible to identify a heuristic for the order in which candidates are attempted. Care must be taken here: The effect of candidate sorting can compound at each step of the solve process, so the time spent sorting has to be more than offset by the typical payoff when applying the heuristic.</span></p>
<p><span style="font-size: 16px;"><strong>Optimization Opportunity: Dealing with Cycles</strong></span></p>
<p><span style="font-size: 16px;">In some (not all) search problems, there is a risk of cycles. That is, a sequence of moves within a search space may lead back to a previously visited configuration of the problem instance. Graph colouring problems (e.g., Sudoku) aren't vulnerable to this possibility, but many puzzles are. Therefore, the solve process must have some way of detecting/avoiding cycles. This gives rise to the use of techniques for efficiently encoding details of the search history and for quickly detecting whether the next configuration is the same as an already-visited configuration - perhaps using hashing.</span></p>
<p><span style="font-size: 16px;"><strong>Optimization Opportunity: Other</strong></span></p>
<p><span style="font-size: 16px;">Don't forget that there may be project-specific techniques to consider.</span></p></body></html>